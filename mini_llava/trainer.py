from transformers import Trainer, TrainingArguments, TrainerCallback
from peft import LoraConfig, get_peft_model
import math

class MMTrainer(Trainer):
    def __init__(self, *args, custom_train_dataloader=None, **kwargs):
        super().__init__(*args, **kwargs)
        self.custom_train_dataloader = custom_train_dataloader
    def get_train_dataloader(self):
        return self.custom_train_dataloader

# é€”ä¸­çµŒéã‚’å¼·åˆ¶çš„ã«è¡¨ç¤ºã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
class SimplePrinter(TrainerCallback):
    def on_log(self, args, state, control, logs=None, **kwargs):
        if not logs: return
        # ä¾‹: {'loss': 3.21, 'grad_norm': 0.9, 'learning_rate': 5e-5, 'epoch': 0.12, 'step': 10}
        step = int(state.global_step)
        maxs = state.max_steps if state.max_steps is not None else "?"
        print(f"[log] step {step}/{maxs} | logs: "
              f"{ {k: round(v,4) if isinstance(v,(int,float)) else v for k,v in logs.items()} }",
              flush=True)   # ğŸ‘ˆ è¿½åŠ 

def train_mini_llava_2(model, tokenizer, train_dataloader, eval_dataloader=None, use_lora=False,
                     max_steps=200,  # â† ã‚¹ãƒ¢ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆç”¨ã€‚ã¡ã‚ƒã‚“ã¨å›ã™æ™‚ã¯å¢—ã‚„ã™/å¤–ã™
                     num_train_epochs=1,  # max_steps ã‚’å„ªå…ˆã€‚å¤–ã™ãªã‚‰ epoch æŒ‡å®šã§ã‚‚OK
                     learning_rate=5e-5):

    # Colabã§é‡ããªã‚ŠãŒã¡ãªã®ã§è»½é‡è¨­å®šï¼†ãƒ­ã‚°å¤šã‚
    training_args = TrainingArguments(
        output_dir="/content/Mini-LLaVA/results",
        # é€²æ—/ä¿å­˜/è©•ä¾¡ã®é »åº¦
        logging_strategy="steps",
        logging_steps=1,           # â† 1ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ãƒ­ã‚°
        logging_first_step=True,    # â† æœ€åˆã®1ã‚¹ãƒ†ãƒƒãƒ—ç›®ã‹ã‚‰å‡ºã™
        save_strategy="steps",
        save_steps=200,             # â† ã‚¹ãƒ¢ãƒ¼ã‚¯ä¸­ã¯å¤§ãã‚ã§OK
        eval_steps=200,
        report_to="none",           # wandbç­‰ã‚’ä½¿ã‚ãªã„
        disable_tqdm=False,         # é€²æ—ãƒãƒ¼ã‚’å‡ºã™

        # å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—åˆ¶å¾¡
        num_train_epochs=num_train_epochs,
        max_steps=max_steps,        # â† ã“ã‚ŒãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹ã¨ epoch ã‚ˆã‚Šå„ªå…ˆã•ã‚Œã‚‹

        # æ€§èƒ½/å®‰å®šåŒ–ç³»
        learning_rate=learning_rate,
        warmup_steps=0,             # å°è¦æ¨¡ãªã®ã§0æ¨å¥¨ï¼ˆ500ã¯é‡ã™ãï¼‰
        weight_decay=0.01,
        gradient_accumulation_steps=1,

        # GPU/ãƒ¡ãƒ¢ãƒª
        fp16=True,                  # T4 ã¯ fp16 å¯
        bf16=False,
        dataloader_num_workers=2,   # ç”»åƒèª­ã¿è¾¼ã¿ã‚’å°‘ã—ä¸¦åˆ—åŒ–
        dataloader_pin_memory=True,

        # ã“ã‚Œè¶…é‡è¦ï¼šã‚«ã‚¹ã‚¿ãƒ dictã‚’ãã®ã¾ã¾Trainerã«æ¸¡ã™ãŸã‚ã«åˆ—å‰Šé™¤ã‚’ç„¡åŠ¹åŒ–
        remove_unused_columns=False,
    )

    # å‚è€ƒï¼šç·ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¦‹ç©ã‚‚ã£ã¦äº‹å‰ã«è¡¨ç¤ºï¼ˆå®‰å¿ƒç”¨ï¼‰
    steps_per_epoch = len(train_dataloader)
    est_total = max_steps if max_steps and max_steps > 0 else math.ceil(steps_per_epoch * num_train_epochs)
    print(f"[info] steps/epoch = {steps_per_epoch}, äºˆå®šç·ã‚¹ãƒ†ãƒƒãƒ— â‰ˆ {est_total}")

    # LoRAï¼ˆmm_projector ã ã‘LoRAåŒ–ã™ã‚‹è¨­è¨ˆã®ã¾ã¾ï¼‰
    if use_lora:
        lora_config = LoraConfig(
            r=16, lora_alpha=32, target_modules=["mm_projector"],
            lora_dropout=0.05, bias="none", task_type="CAUSAL_LM"
        )
        model = get_peft_model(model, lora_config)

    trainer = MMTrainer(
        model=model,
        args=training_args,
        custom_train_dataloader=train_dataloader,
        tokenizer=tokenizer
    )
    trainer.add_callback(SimplePrinter())  # â† ãƒ­ã‚°å‡ºåŠ›ã‚’ç¢ºå®ŸåŒ–

    # å­¦ç¿’
    trainer.train()

    # ä¿å­˜
    trainer.save_model("/content/Mini-LLaVA/final_model")
    print("âœ… Model saved to /content/Mini-LLaVA/final_model")
